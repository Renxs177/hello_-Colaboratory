{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Los Angeles Traffic with Graphical Neural Networks",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renxs177/hello_-Colaboratory/blob/main/Predicting_Los_Angeles_Traffic_with_Graphical_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# Predicting Los Angeles Traffic with Graphical Neural Networks\n",
        "by Julie Wang, Amelia Woodward, Tracy Cai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxG3DeP7HVLn"
      },
      "source": [
        "This notebook accompanies our Medium post on predicting LA Traffic with GNNs. Specifically, it deploys our implementation of the ST-GAT presented by Zhang et al n \"Spatial-Temporal Graph Attention Networks: A Deep Learning Approach for Traffic Forecasting\".\n",
        "\n",
        "This code can also be viewed as a github repo in https://github.com/jswang/cs224w_traffic_prediction. \n",
        "\n",
        "We will walk through the following steps: \n",
        "1.   Installation and Setup\n",
        "2.   Creating a dataloader\n",
        "3.   Building the Model\n",
        "4.   Creating train and evaluation functions\n",
        "5.   Train the model\n",
        "6.   Test the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation and setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "We recommend using a GPU for running our project.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OraOHb9w5-o_",
        "outputId": "ce52b631-c4ca-4475-9976-176955a69901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x207Q4T_C_w7"
      },
      "source": [
        "Install PyTorch, PyG, and other necessary python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "d397dd74-c4b3-4c96-cbac-32717ca21c85"
      },
      "source": [
        "# Install torch geometric\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 11.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.2.tar.gz (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.2-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.2-py3-none-any.whl size=535570 sha256=b4dda1d28d2b58ac7beb9ac612d5cc047638b770b340f025f3439e3302370225\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/08/13/2321517088bb2e95bfd0e45033bb9c923189e5b2078e0be4ef\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.2 torch-geometric-2.0.2 yacs-0.1.8\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=2e4daf7d0b36664da147854d5ab12b68c7c5c9776a14d9a6ad580a7da2392735\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google for output directories"
      ],
      "metadata": {
        "id": "Ok7A5EQM6VEU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "f5af7c3b-fa3c-496e-dc39-41d796bcc330"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd '/content/'\n",
        "!git clone https://github.com/jswang/stgat_traffic_prediction.git\n",
        "%cd stgat_traffic_prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Cloning into 'stgat_traffic_prediction'...\n",
            "remote: Enumerating objects: 693, done.\u001b[K\n",
            "remote: Counting objects: 100% (693/693), done.\u001b[K\n",
            "remote: Compressing objects: 100% (369/369), done.\u001b[K\n",
            "remote: Total 693 (delta 369), reused 634 (delta 311), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (693/693), 22.98 MiB | 14.01 MiB/s, done.\n",
            "Resolving deltas: 100% (369/369), done.\n",
            "/content/stgat_traffic_prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Dataloader\n",
        "Now, we create a dataloader which will process data from `.csv` files into a PyTorch Geometric dataset. "
      ],
      "metadata": {
        "id": "nqOWp_S591MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "def distance_to_weight(W, sigma2=0.1, epsilon=0.5, gat_version=False):\n",
        "    \"\"\"\"\n",
        "    Given distances between all nodes, convert into a weight matrix\n",
        "    :param W distances\n",
        "    :param sigma2 User configurable parameter to adjust sparsity of matrix\n",
        "    :param epsilon User configurable parameter to adjust sparsity of matrix\n",
        "    :param gat_version If true, use 0/1 weights with self loops. Otherwise, use float\n",
        "    \"\"\"\n",
        "    n = W.shape[0]\n",
        "    W = W / 10000.\n",
        "    W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
        "    # refer to Eq.10\n",
        "    W = np.exp(-W2 / sigma2) * (np.exp(-W2 / sigma2) >= epsilon) * W_mask\n",
        "\n",
        "    # If using the gat version of this, round to 0/1 and include self loops\n",
        "    if gat_version:\n",
        "        W[W>0] = 1\n",
        "        W += np.identity(n)\n",
        "\n",
        "    return W\n",
        "\n",
        "class TrafficDataset(InMemoryDataset):\n",
        "    \"\"\"\n",
        "    Dataset for Graph Neural Networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, W, root='', transform=None, pre_transform=None):\n",
        "        self.config = config\n",
        "        self.W = W\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices, self.n_node, self.mean, self.std_dev = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [os.path.join(self.raw_dir, 'PeMSD7_V_228.csv')]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['./data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        copyfile('./dataset/PeMSD7_V_228.csv', os.path.join(self.raw_dir, 'PeMSD7_V_228.csv'))\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"\n",
        "        Process the raw datasets into saved .pt dataset for later use.\n",
        "        Note that any self.fields here wont exist if loading straight from the .pt file\n",
        "        \"\"\"\n",
        "        # Data Preprocessing and loading\n",
        "        data = pd.read_csv(self.raw_file_names[0], header=None).values\n",
        "        # Technically using the validation and test datasets here, but it's fine, would normally get the\n",
        "        # mean and std_dev from a large dataset\n",
        "        mean =  np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "        data = z_score(data, np.mean(data), np.std(data))\n",
        "\n",
        "        _, n_node = data.shape\n",
        "        n_window = self.config['N_PRED'] + self.config['N_HIST']\n",
        "\n",
        "        # manipulate nxn matrix into 2xnum_edges\n",
        "        edge_index = torch.zeros((2, n_node**2), dtype=torch.long)\n",
        "        # create an edge_attr matrix with our weights  (num_edges x 1) --> our edge features are dim 1\n",
        "        edge_attr = torch.zeros((n_node**2, 1))\n",
        "        num_edges = 0\n",
        "        for i in range(n_node):\n",
        "            for j in range(n_node):\n",
        "                if self.W[i, j] != 0.:\n",
        "                    edge_index[0, num_edges] = i\n",
        "                    edge_index[1, num_edges] = j\n",
        "                    edge_attr[num_edges] = self.W[i, j]\n",
        "                    num_edges += 1\n",
        "        # using resize_ to just keep the first num_edges entries\n",
        "        edge_index = edge_index.resize_(2, num_edges)\n",
        "        edge_attr = edge_attr.resize_(num_edges, 1)\n",
        "\n",
        "        sequences = []\n",
        "        # T x F x N\n",
        "        for i in range(self.config['N_DAYS']):\n",
        "            for j in range(self.config['N_SLOT']):\n",
        "                # for each time point construct a different graph with data object\n",
        "                # Docs here: https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n",
        "                g = Data()\n",
        "                g.__num_nodes__ = n_node\n",
        "\n",
        "                g.edge_index = edge_index\n",
        "                g.edge_attr  = edge_attr\n",
        "\n",
        "                # (F,N) switched to (N,F)\n",
        "                sta = i * self.config['N_DAY_SLOT'] + j\n",
        "                end = sta + n_window\n",
        "                # [21, 228]\n",
        "                full_window = np.swapaxes(data[sta:end, :], 0, 1)\n",
        "                g.x = torch.FloatTensor(full_window[:, 0:self.config['N_HIST']])\n",
        "                g.y = torch.FloatTensor(full_window[:, self.config['N_HIST']::])\n",
        "                sequences += [g]\n",
        "\n",
        "        # Make the actual dataset\n",
        "        data, slices = self.collate(sequences)\n",
        "        torch.save((data, slices, n_node, mean, std_dev), self.processed_paths[0])\n",
        "\n",
        "def get_splits(dataset: TrafficDataset, n_slot, splits):\n",
        "    \"\"\"\n",
        "    Given the data, split it into random subsets of train, val, and test as given by splits\n",
        "    :param dataset: TrafficDataset object to split\n",
        "    :param n_slot: Number of possible sliding windows in a day\n",
        "    :param splits: (train, val, test) ratios\n",
        "    \"\"\"\n",
        "    split_train, split_val, _ = splits\n",
        "    i = n_slot*split_train\n",
        "    j = n_slot*split_val\n",
        "    train = dataset[:i]\n",
        "    val = dataset[i:i+j]\n",
        "    test = dataset[i+j:]\n",
        "\n",
        "    return train, val, test\n"
      ],
      "metadata": {
        "id": "TEKy_v5EFPMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "#Build the Model\n",
        "\n",
        "Using PyG's built in layers, create a Spatio-Temporal Graph as presented in https://ieeexplore.ieee.org/document/8903252. \n",
        "\n",
        "Ths model is a Pytorch model containing an initialization function for setting up the model architecture, and a forward function for performing a forward pass of data through the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "class ST_GAT(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-Temporal Graph Attention Network as presented in https://ieeexplore.ieee.org/document/8903252\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, n_nodes, heads=8, dropout=0.0):\n",
        "        \"\"\"\n",
        "        Initialize the ST-GAT model\n",
        "        :param in_channels Number of input channels\n",
        "        :param out_channels Number of output channels\n",
        "        :param n_nodes Number of nodes in the graph\n",
        "        :param heads Number of attention heads to use in graph\n",
        "        :param dropout Dropout probability on output of Graph Attention Network\n",
        "        \"\"\"\n",
        "        super(ST_GAT, self).__init__()\n",
        "        self.n_pred = out_channels\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.n_nodes = n_nodes\n",
        "\n",
        "        self.n_preds = 9\n",
        "        lstm1_hidden_size = 32\n",
        "        lstm2_hidden_size = 128\n",
        "\n",
        "        # single graph attentional layer with 8 attention heads\n",
        "        self.gat = GATConv(in_channels=in_channels, out_channels=in_channels,\n",
        "            heads=heads, dropout=0, concat=False)\n",
        "\n",
        "        # add two LSTM layers\n",
        "        self.lstm1 = torch.nn.LSTM(input_size=self.n_nodes, hidden_size=lstm1_hidden_size, num_layers=1)\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                torch.nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "        self.lstm2 = torch.nn.LSTM(input_size=lstm1_hidden_size, hidden_size=lstm2_hidden_size, num_layers=1)\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                torch.nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "\n",
        "        # fully-connected neural network\n",
        "        self.linear = torch.nn.Linear(lstm2_hidden_size, self.n_nodes*self.n_pred)\n",
        "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
        "\n",
        "    def forward(self, data, device):\n",
        "        \"\"\"\n",
        "        Forward pass of the ST-GAT model\n",
        "        :param data Data to make a pass on\n",
        "        :param device Device to operate on\n",
        "        \"\"\"\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # apply dropout\n",
        "        if device == 'cpu':\n",
        "            x = torch.FloatTensor(x)\n",
        "        else:\n",
        "            x = torch.cuda.FloatTensor(x)\n",
        "\n",
        "        # gat layer: output of gat: [11400, 12]\n",
        "        x = self.gat(x, edge_index)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        # RNN: 2 LSTM\n",
        "        # [batchsize*n_nodes, seq_length] -> [batch_size, n_nodes, seq_length]\n",
        "        batch_size = data.num_graphs\n",
        "        n_node = int(data.num_nodes/batch_size)\n",
        "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
        "        # for lstm: x should be (seq_length, batch_size, n_nodes)\n",
        "        # sequence length = 12, batch_size = 50, n_node = 228\n",
        "        x = torch.movedim(x, 2, 0)\n",
        "        # [12, 50, 228] -> [12, 50, 32]\n",
        "        x, _ = self.lstm1(x)\n",
        "        # [12, 50, 32] -> [12, 50, 128]\n",
        "        x, _ = self.lstm2(x)\n",
        "\n",
        "        # Output contains h_t for each timestep, only the last one has all input's accounted for\n",
        "        # [12, 50, 128] -> [50, 128]\n",
        "        x = torch.squeeze(x[-1, :, :])\n",
        "        # [50, 128] -> [50, 228*9]\n",
        "        x = self.linear(x)\n",
        "\n",
        "        # Now reshape into final output\n",
        "        s = x.shape\n",
        "        # [50, 228*9] -> [50, 228, 9]\n",
        "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
        "        # [50, 228, 9] ->  [11400, 9]\n",
        "        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "B7jt96q77EZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Train and Evaluation functions\n",
        "\n",
        "Create a train function which performs a forward and a backward pass using the model.\n",
        "\n",
        "Create an evaluation function which performs only a forward pass using the model.\n",
        "\n",
        "These functions will be used in various stages of overall model training and testing."
      ],
      "metadata": {
        "id": "W42pHHlz7GUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval(model, device, dataloader, type=''):\n",
        "    \"\"\"\n",
        "    Evaluation function to evaluate model on data\n",
        "    :param model Model to evaluate\n",
        "    :param device Device to evaluate on\n",
        "    :param dataloader Data loader\n",
        "    :param type Name of evaluation type, e.g. Train/Val/Test\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    mae = 0\n",
        "    rmse = 0\n",
        "    mape = 0\n",
        "    n = 0\n",
        "\n",
        "    # Evaluate model on all data\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        batch = batch.to(device)\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                pred = model(batch, device)\n",
        "            truth = batch.y.view(pred.shape)\n",
        "            if i == 0:\n",
        "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
        "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
        "            truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
        "            pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
        "            y_pred[i, :pred.shape[0], :] = pred\n",
        "            y_truth[i, :pred.shape[0], :] = truth\n",
        "            rmse += RMSE(truth, pred)\n",
        "            mae += MAE(truth, pred)\n",
        "            mape += MAPE(truth, pred)\n",
        "            n += 1\n",
        "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
        "\n",
        "    print(f'{type}, MAE: {mae}, RMSE: {rmse}, MAPE: {mape}')\n",
        "\n",
        "    #get the average score for each metric in each batch\n",
        "    return rmse, mae, mape, y_pred, y_truth\n",
        "\n",
        "def train(model, device, dataloader, optimizer, loss_fn, epoch):\n",
        "    \"\"\"\n",
        "    Evaluation function to evaluate model on data\n",
        "    :param model Model to evaluate\n",
        "    :param device Device to evaluate on\n",
        "    :param dataloader Data loader\n",
        "    :param optimizer Optimizer to use\n",
        "    :param loss_fn Loss function\n",
        "    :param epoch Current epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = torch.squeeze(model(batch, device))\n",
        "        loss = loss_fn()(y_pred.float(), torch.squeeze(batch.y).float())\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "mcifitQO7uag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to evaluation the performance of the model, we need to define some evaluation metrics.  \n",
        "\n",
        "*   The Z-score normalizes data using mean and std deviation.\n",
        "*   MAPE is mean average percentage error. \n",
        "*   RMSE is root mean square error.\n",
        "*   MAE is mean absolute error. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N6tXJUu38HGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def z_score(x, mean, std):\n",
        "    \"\"\"\n",
        "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
        "    where z is the z-score, X is the value of the element,\n",
        "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
        "    :param x: torch array, input array to be normalized.\n",
        "    :param mean: float, the value of mean.\n",
        "    :param std: float, the value of standard deviation.\n",
        "    :return: torch array, z-score normalized array.\n",
        "    \"\"\"\n",
        "    return (x - mean) / std\n",
        "\n",
        "def un_z_score(x_normed, mean, std):\n",
        "    \"\"\"\n",
        "    Undo the Z-score calculation\n",
        "    :param x_normed: torch array, input array to be un-normalized.\n",
        "    :param mean: float, the value of mean.\n",
        "    :param std: float, the value of standard deviation.\n",
        "    \"\"\"\n",
        "    return x_normed * std  + mean\n",
        "\n",
        "\n",
        "def MAPE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean absolute percentage error, given as a % (e.g. 99 -> 99%)\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, MAPE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.abs((v_ - v)) /(v + 1e-15) * 100)\n",
        "\n",
        "\n",
        "def RMSE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean squared error.\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, RMSE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.sqrt(torch.mean((v_ - v) ** 2))\n",
        "\n",
        "\n",
        "def MAE(v, v_):\n",
        "    \"\"\"\n",
        "    Mean absolute error.\n",
        "    :param v: torch array, ground truth.\n",
        "    :param v_: torch array, prediction.\n",
        "    :return: torch scalar, MAE averages on all elements of input.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.abs(v_ - v))\n"
      ],
      "metadata": {
        "id": "0CP54Sdb8HRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's put it all together. Let's use the `train` and `eval` functions along with the model and dataloadres to create a training function (`model_train`) and testing function (`model_test`).\n",
        "\n",
        "We also build in tensorboard support for logging of the training metrics over time.\n"
      ],
      "metadata": {
        "id": "RQmkAf1W7z2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Make a tensorboard writer\n",
        "writer = SummaryWriter()\n",
        "\n",
        "def model_train(train_dataloader, val_dataloader, config, device):\n",
        "    \"\"\"\n",
        "    Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
        "    :param train_dataloader Data loader of training dataset\n",
        "    :param val_dataloader Dataloader of val dataset\n",
        "    :param config configuration to use\n",
        "    :param device Device to evaluate on\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the model. Each datapoint in the graph is 228x12: N x F (N = # nodes, F = time window)\n",
        "    model = ST_GAT(in_channels=config['N_HIST'], out_channels=config['N_PRED'], n_nodes=config['N_NODE'], dropout=config['DROPOUT'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'], weight_decay=config['WEIGHT_DECAY'])\n",
        "    loss_fn = torch.nn.MSELoss\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n",
        "    for epoch in range(config['EPOCHS']):\n",
        "        loss = train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
        "        print(f\"Loss: {loss:.3f}\")\n",
        "        if epoch % 5 == 0:\n",
        "            train_mae, train_rmse, train_mape, _, _ = eval(model, device, train_dataloader, 'Train')\n",
        "            val_mae, val_rmse, val_mape, _, _ = eval(model, device, val_dataloader, 'Valid')\n",
        "            writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n",
        "            writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n",
        "            writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n",
        "            writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n",
        "            writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n",
        "            writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n",
        "\n",
        "    writer.flush()\n",
        "    # Save the model\n",
        "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
        "    torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss,\n",
        "            }, os.path.join(config[\"CHECKPOINT_DIR\"], f\"model_{timestr}.pt\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def model_test(model, test_dataloader, device, config):\n",
        "    \"\"\"\n",
        "    Test the ST-GAT model\n",
        "    :param test_dataloader Data loader of test dataset\n",
        "    :param device Device to evaluate on\n",
        "    \"\"\"\n",
        "    _, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n"
      ],
      "metadata": {
        "id": "iwQHMBp975LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Start training\n",
        "\n",
        "Now with all code in place, let's set up config, load our dataset, and start training!"
      ],
      "metadata": {
        "id": "zUj42a8B_6wE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, to watch your training over time, load the tensorboard extension"
      ],
      "metadata": {
        "id": "HC3ssSNGGU0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "kbA6aPl0GH-F",
        "outputId": "c4c243b6-4614-4812-8e3a-c746f0ce527c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m此单元格的输出内容太大，只能在登录的情况下显示。\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, create your dataloaders and start training!\n",
        "\n",
        "In our default configuration, we train for 60 epochs with a batch size of 50. You can view your training progress in the tensorboard above by clicking the \"refresh\" button to see new data. Training and validation performance are updated every 5 epochs."
      ],
      "metadata": {
        "id": "OyZlmf8BGZx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Constant config to use throughout\n",
        "config = {\n",
        "    'BATCH_SIZE': 50,\n",
        "    'EPOCHS': 60,\n",
        "    'WEIGHT_DECAY': 5e-5,\n",
        "    'INITIAL_LR': 3e-4,\n",
        "    'CHECKPOINT_DIR': './runs',\n",
        "    'N_PRED': 9,\n",
        "    'N_HIST': 12,\n",
        "    'DROPOUT': 0.2,\n",
        "    # number of possible 5 minute measurements per day\n",
        "    'N_DAY_SLOT': 288,\n",
        "    # number of days worth of data in the dataset\n",
        "    'N_DAYS': 44,\n",
        "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
        "    'USE_GAT_WEIGHTS': True,\n",
        "    'N_NODE': 228,\n",
        "}\n",
        "# Number of possible windows in a day\n",
        "config['N_SLOT']= config['N_DAY_SLOT'] - (config['N_PRED']+config['N_HIST']) + 1\n",
        "\n",
        "# Load the weight and dataset dataset\n",
        "distances = pd.read_csv('./dataset/PeMSD7_W_228.csv', header=None).values\n",
        "W = distance_to_weight(distances, gat_version=config['USE_GAT_WEIGHTS'])\n",
        "dataset = TrafficDataset(config, W)\n",
        "\n",
        "# total of 44 days in the dataset, use 34 for training, 5 for val, 5 for test\n",
        "d_train, d_val, d_test = get_splits(dataset, config['N_SLOT'], (34, 5, 5))\n",
        "train_dataloader = DataLoader(d_train, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
        "val_dataloader = DataLoader(d_val, batch_size=config['BATCH_SIZE'], shuffle=True)\n",
        "test_dataloader = DataLoader(d_test, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "# Get gpu if you can\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "# Configure and train model\n",
        "config['N_NODE'] = dataset.n_node\n",
        "model = model_train(train_dataloader, val_dataloader, config, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFwnhhQJCEOO",
        "outputId": "2c50f969-84e0-4e0f-f1b5-f8329a806b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 183/183 [00:06<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.256\n",
            "Train, MAE: 5.0243940353393555, RMSE: 7.9125165939331055, MAPE: 13.189617156982422\n",
            "Valid, MAE: 5.053834915161133, RMSE: 7.847815036773682, MAPE: 13.16602611541748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 183/183 [00:04<00:00, 38.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 183/183 [00:03<00:00, 45.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 183/183 [00:03<00:00, 45.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 183/183 [00:03<00:00, 45.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 183/183 [00:04<00:00, 45.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.236\n",
            "Train, MAE: 3.7368552684783936, RMSE: 6.391045570373535, MAPE: 9.523011207580566\n",
            "Valid, MAE: 3.9742846488952637, RMSE: 6.76729154586792, MAPE: 9.99803638458252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 183/183 [00:04<00:00, 45.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 183/183 [00:04<00:00, 45.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 183/183 [00:04<00:00, 45.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 183/183 [00:04<00:00, 45.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 183/183 [00:04<00:00, 45.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.218\n",
            "Train, MAE: 3.431297779083252, RMSE: 5.894279479980469, MAPE: 8.705282211303711\n",
            "Valid, MAE: 3.790898084640503, RMSE: 6.53023624420166, MAPE: 9.536735534667969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 183/183 [00:03<00:00, 46.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 183/183 [00:04<00:00, 45.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 183/183 [00:03<00:00, 45.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 183/183 [00:03<00:00, 46.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 183/183 [00:03<00:00, 46.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.224\n",
            "Train, MAE: 3.262099504470825, RMSE: 5.56423807144165, MAPE: 8.141607284545898\n",
            "Valid, MAE: 3.7339463233947754, RMSE: 6.402459621429443, MAPE: 9.295312881469727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 183/183 [00:03<00:00, 46.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 183/183 [00:03<00:00, 45.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 183/183 [00:03<00:00, 46.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 183/183 [00:03<00:00, 45.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 183/183 [00:03<00:00, 46.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.211\n",
            "Train, MAE: 3.1487669944763184, RMSE: 5.3401103019714355, MAPE: 7.7841949462890625\n",
            "Valid, MAE: 3.733562707901001, RMSE: 6.39630651473999, MAPE: 9.200615882873535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 183/183 [00:03<00:00, 45.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 183/183 [00:03<00:00, 45.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 183/183 [00:03<00:00, 45.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 183/183 [00:03<00:00, 46.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 183/183 [00:03<00:00, 46.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.125\n",
            "Train, MAE: 3.0864126682281494, RMSE: 5.18549919128418, MAPE: 7.59406042098999\n",
            "Valid, MAE: 3.7119662761688232, RMSE: 6.33851957321167, MAPE: 9.20683479309082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 183/183 [00:03<00:00, 46.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 183/183 [00:04<00:00, 45.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 183/183 [00:03<00:00, 45.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 183/183 [00:03<00:00, 45.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 183/183 [00:04<00:00, 45.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.167\n",
            "Train, MAE: 3.028179168701172, RMSE: 5.074080944061279, MAPE: 7.4495320320129395\n",
            "Valid, MAE: 3.6957664489746094, RMSE: 6.333939075469971, MAPE: 9.153971672058105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 183/183 [00:04<00:00, 45.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 183/183 [00:04<00:00, 45.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 183/183 [00:04<00:00, 45.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 183/183 [00:03<00:00, 45.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 183/183 [00:04<00:00, 44.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.134\n",
            "Train, MAE: 2.997509717941284, RMSE: 4.9981865882873535, MAPE: 7.287314414978027\n",
            "Valid, MAE: 3.7374982833862305, RMSE: 6.392979621887207, MAPE: 9.167180061340332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 183/183 [00:03<00:00, 46.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 183/183 [00:04<00:00, 45.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 183/183 [00:03<00:00, 45.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 183/183 [00:03<00:00, 46.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 183/183 [00:04<00:00, 45.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.121\n",
            "Train, MAE: 2.9529385566711426, RMSE: 4.916229724884033, MAPE: 7.194719314575195\n",
            "Valid, MAE: 3.7182185649871826, RMSE: 6.366259574890137, MAPE: 9.16735553741455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41: 100%|██████████| 183/183 [00:03<00:00, 46.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42: 100%|██████████| 183/183 [00:03<00:00, 45.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43: 100%|██████████| 183/183 [00:03<00:00, 45.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44: 100%|██████████| 183/183 [00:04<00:00, 45.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45: 100%|██████████| 183/183 [00:04<00:00, 44.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.119\n",
            "Train, MAE: 2.9275946617126465, RMSE: 4.853134632110596, MAPE: 7.141767501831055\n",
            "Valid, MAE: 3.740072250366211, RMSE: 6.3743367195129395, MAPE: 9.209250450134277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46: 100%|██████████| 183/183 [00:04<00:00, 44.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47: 100%|██████████| 183/183 [00:04<00:00, 44.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48: 100%|██████████| 183/183 [00:04<00:00, 45.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49: 100%|██████████| 183/183 [00:03<00:00, 45.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50: 100%|██████████| 183/183 [00:04<00:00, 45.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.152\n",
            "Train, MAE: 2.9007420539855957, RMSE: 4.799988269805908, MAPE: 7.050012588500977\n",
            "Valid, MAE: 3.729079484939575, RMSE: 6.353559970855713, MAPE: 9.162540435791016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51: 100%|██████████| 183/183 [00:04<00:00, 45.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52: 100%|██████████| 183/183 [00:04<00:00, 45.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53: 100%|██████████| 183/183 [00:04<00:00, 45.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54: 100%|██████████| 183/183 [00:04<00:00, 45.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55: 100%|██████████| 183/183 [00:04<00:00, 45.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.165\n",
            "Train, MAE: 2.883657455444336, RMSE: 4.763654708862305, MAPE: 7.03734016418457\n",
            "Valid, MAE: 3.732534408569336, RMSE: 6.3664703369140625, MAPE: 9.234374046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56: 100%|██████████| 183/183 [00:04<00:00, 45.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57: 100%|██████████| 183/183 [00:04<00:00, 45.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58: 100%|██████████| 183/183 [00:04<00:00, 45.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59: 100%|██████████| 183/183 [00:04<00:00, 45.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model\n",
        "\n",
        "Now that we have a trained model, we can test it on the test dataset and visualize its performance"
      ],
      "metadata": {
        "id": "0nm7Xd8CI3Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction(test_dataloader, y_pred, y_truth, node, config):\n",
        "    # Calculate the truth\n",
        "    s = y_truth.shape\n",
        "    y_truth = y_truth.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
        "    # just get the first prediction out for the nth node\n",
        "    y_truth = y_truth[:, :, node, 0]\n",
        "    # Flatten to get the predictions for entire test dataset\n",
        "    y_truth = torch.flatten(y_truth)\n",
        "    day0_truth = y_truth[:config['N_SLOT']]\n",
        "\n",
        "\n",
        "    # Calculate the predicted\n",
        "    s = y_pred.shape\n",
        "    y_pred = y_pred.reshape(s[0], config['BATCH_SIZE'], config['N_NODE'], s[-1])\n",
        "    # just get the first prediction out for the nth node\n",
        "    y_pred = y_pred[:, :, node, 0]\n",
        "    # Flatten to get the predictions for entire test dataset\n",
        "    y_pred = torch.flatten(y_pred)\n",
        "    # Just grab the first day\n",
        "    day0_pred = y_pred[:config['N_SLOT']]\n",
        "    t = [t for t in range(0, config['N_SLOT']*5, 5)]\n",
        "    plt.plot(t, day0_pred, label='ST-GAT')\n",
        "    plt.plot(t, day0_truth, label='truth')\n",
        "    plt.xlabel('Time (minutes)')\n",
        "    plt.ylabel('Speed prediction')\n",
        "    plt.title('Predictions of traffic over time')\n",
        "    plt.legend()\n",
        "    plt.savefig('predicted_times.png')\n",
        "    plt.show()\n",
        "    \n",
        "_, _, _, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
        "plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-_urKxjI2gQ",
        "outputId": "2bcd65c6-0d9a-4f72-d09c-df1c22c01701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test, MAE: 3.848196268081665, RMSE: 6.299871921539307, MAPE: 9.210926055908203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rejoice\n",
        "\n",
        "We hope that you have found this colab informative and useful. Note that our final performance lags that published by the paper slightly, we believe this is due to small differences in training parameters and initializations that were not published with the paper."
      ],
      "metadata": {
        "id": "COGjouriMrDf"
      }
    }
  ]
}